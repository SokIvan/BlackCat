import cv2
import os
import logging
import numpy as np
from pathlib import Path
import json

class FaceTrainer:
    """–û–±—É—á–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ª–∏—Ü –∏—Å–ø–æ–ª—å–∑—É—è OpenCV LBPH"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.recognizer = cv2.face.LBPHFaceRecognizer_create()
    
    def train_from_dataset(self, dataset_path="face_dataset"):
        """
        –û–±—É—á–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ª–∏—Ü
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ
        """
        dataset_path = Path(dataset_path)
        
        if not dataset_path.exists():
            self.logger.error(f"‚ùå –ü–∞–ø–∫–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {dataset_path}")
            return False
        
        faces = []
        labels = []
        label_map = {}
        current_label = 0
        known_face_names = []
        
        self.logger.info("üéØ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ...")
        
        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ
        for person_dir in dataset_path.iterdir():
            if not person_dir.is_dir():
                continue
                
            person_name = person_dir.name
            self.logger.info(f"üë§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {person_name}")
            
            # –ù–∞–∑–Ω–∞—á–∞–µ–º –º–µ—Ç–∫—É –¥–ª—è —ç—Ç–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞
            label_map[current_label] = person_name
            known_face_names.append(person_name)
            
            image_count = 0
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã
            image_files = list(person_dir.glob("*.jpg")) + list(person_dir.glob("*.png")) + list(person_dir.glob("*.jpeg"))
            
            for img_path in image_files:
                try:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    image = cv2.imread(str(img_path))
                    
                    if image is None:
                        self.logger.warning(f"  ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å: {img_path.name}")
                        continue
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale
                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                    
                    # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
                    gray = cv2.resize(gray, (100, 100))
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                    faces.append(gray)
                    labels.append(current_label)
                    image_count += 1
                    
                    self.logger.debug(f"  ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {img_path.name}")
                        
                except Exception as e:
                    self.logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {img_path}: {e}")
                    continue
            
            self.logger.info(f"  üìä –î–ª—è {person_name} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {image_count}")
            
            if image_count == 0:
                self.logger.warning(f"  ‚ö†Ô∏è –í –ø–∞–ø–∫–µ {person_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!")
            else:
                current_label += 1
        
        if len(faces) == 0:
            self.logger.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ª–∏—Ü–∞ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ!")
            return False
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        self.logger.info("üß† –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å LBPH...")
        self.recognizer.train(faces, np.array(labels))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ –º–µ—Ç–∫–∏
        db_path = Path("known_faces_db")
        db_path.mkdir(exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        self.recognizer.save(str(db_path / "face_model.yml"))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∫–∏
        labels_data = {
            'names': known_face_names,
            'label_map': label_map,
            'total_samples': len(faces),
            'unique_persons': len(known_face_names)
        }
        
        with open(db_path / "labels.json", 'w', encoding='utf-8') as f:
            json.dump(labels_data, f, indent=2, ensure_ascii=False)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        import datetime
        metadata = {
            'total_faces': len(faces),
            'unique_persons': len(known_face_names),
            'trained_at': str(datetime.datetime.now()),
            'model_used': 'OpenCV_LBPH'
        }
        
        with open(db_path / "metadata.json", 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        self.logger.info(f"üìä –í—Å–µ–≥–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(faces)}")
        self.logger.info(f"üë• –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {len(known_face_names)}")
        
        return True

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"""
    import logging
    logging.basicConfig(level=logging.INFO)
    
    print("üéØ –û–ë–£–ß–ï–ù–ò–ï –°–ò–°–¢–ï–ú–´ –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø –õ–ò–¶ (OpenCV LBPH)")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ OpenCV —Å –º–æ–¥—É–ª–µ–º face
    try:
        import cv2
        cv2.face.LBPHFaceRecognizer_create()
    except AttributeError:
        print("‚ùå –û—à–∏–±–∫–∞: –í –≤–∞—à–µ–π –≤–µ—Ä—Å–∏–∏ OpenCV –Ω–µ—Ç –º–æ–¥—É–ª—è face!")
        print("üí° –†–µ—à–µ–Ω–∏–µ: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ opencv-contrib-python:")
        print("   pip uninstall opencv-python")
        print("   pip install opencv-contrib-python")
        return
    
    trainer = FaceTrainer()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
    if not Path("face_dataset").exists():
        print("‚ùå –ü–∞–ø–∫–∞ 'face_dataset' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        print("üìÅ –°–æ–∑–¥–∞–π—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É:")
        print("face_dataset/")
        print("‚îú‚îÄ‚îÄ owner/       # –í–∞—à–∏ —Ñ–æ—Ç–æ (10-15 —à—Ç—É–∫)")
        print("‚îú‚îÄ‚îÄ person1/     # –î—Ä—É–≥–∏–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ª—é–¥–∏")
        print("‚îî‚îÄ‚îÄ ...")
        print("\nüí° –°–æ–≤–µ—Ç—ã –ø–æ —Ñ–æ—Ç–æ:")
        print("- –•–æ—Ä–æ—à–µ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ")
        print("- –†–∞–∑–Ω—ã–µ —Ä–∞–∫—É—Ä—Å—ã")
        print("- –†–∞–∑–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –ª–∏—Ü–∞")
        print("- –†–∞–∑–º–µ—Ä —Ñ–æ—Ç–æ: –º–∏–Ω–∏–º—É–º 100x100 –ø–∏–∫—Å–µ–ª–µ–π")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ–æ—Ç–æ –≤ –ø–∞–ø–∫–∞—Ö
    has_images = False
    for person_dir in Path("face_dataset").iterdir():
        if person_dir.is_dir():
            images = list(person_dir.glob("*.jpg")) + list(person_dir.glob("*.png")) + list(person_dir.glob("*.jpeg"))
            if images:
                has_images = True
                print(f"üìÅ {person_dir.name}: {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    if not has_images:
        print("‚ùå –í –ø–∞–ø–∫–∞—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!")
        print("üí° –î–æ–±–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JPG, PNG –∏–ª–∏ JPEG")
        return
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
    success = trainer.train_from_dataset()
    
    if success:
        print("\n‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        print("üí° –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∏—Å—Ç–µ–º—É –æ—Ö—Ä–∞–Ω—ã:")
        print("   python main.py")
    else:
        print("\n‚ùå –û–ë–£–ß–ï–ù–ò–ï –ù–ï –£–î–ê–õ–û–°–¨!")

if __name__ == "__main__":
    main()